{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIVARIATE__LSTM_Time_Series_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***UNIVARIATE LSTM MODELS***\n",
        "\n",
        "Univariate LSTM Models\n",
        "LSTMs can be used to model univariate time series forecasting problems.\n",
        "\n",
        "These are problems comprised of a single series of observations and a model is required to learn from the series of past observations to predict the next value in the sequence.\n",
        "\n",
        "We will demonstrate a number of variations of the LSTM model for univariate time series forecasting.\n",
        "\n",
        "This section is divided into six parts; they are:\n",
        "\n",
        "### ***DATA PREPARATION***\n",
        "\n",
        "Vanilla LSTM\n",
        "Stacked LSTM\n",
        "Bidirectional LSTM\n",
        "CNN LSTM\n",
        "ConvLSTM\n",
        "Each of these models are demonstrated for one-step univariate time series forecasting, but can easily be adapted and used as the input part of a model for other types of time series forecasting problems.\n",
        "\n",
        "Data Preparation\n",
        "Before a univariate series can be modeled, it must be prepared.\n",
        "\n",
        "The LSTM model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the LSTM can learn.\n",
        "\n",
        "Consider a given univariate sequence:\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n",
        "\n",
        "     X          y\n",
        "\n",
        "10, 20, 30\t-\t 40\n",
        "\n",
        "20, 30, 40\t-\t 50\n",
        "\n",
        "30, 40, 50\t-\t 60\n",
        "\n",
        "The split_sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step.\n",
        "\n",
        "We can demonstrate this function on our small contrived dataset above.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "v-VkzpW8-CJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "VLV7-BxGKa5g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnDTuUt47PAR",
        "outputId": "3d9e99cb-84d2-4235-d804-7faf268216fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 20 30] 40\n",
            "[20 30 40] 50\n",
            "[30 40 50] 60\n",
            "[40 50 60] 70\n",
            "[50 60 70] 80\n",
            "[60 70 80] 90\n"
          ]
        }
      ],
      "source": [
        "# univariate data preparation\n",
        "from numpy import array\n",
        " \n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "\tprint(X[i], y[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example splits the univariate series into six samples where each sample has three input time steps and one output time step.\n",
        "\n",
        "Now that we know how to prepare a univariate series for modeling, let’s look at developing LSTM models that can learn the mapping of inputs to outputs, starting with a Vanilla LSTM."
      ],
      "metadata": {
        "id": "ZuqNy_ze-4rD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "DVx282tW_at_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***VANILLA LSTM***\n",
        "\n",
        "A Vanilla LSTM is an LSTM model that has a single hidden layer of LSTM units, and an output layer used to make a prediction.\n",
        "\n",
        "We can define a Vanilla LSTM for univariate time series forecasting as follows."
      ],
      "metadata": {
        "id": "C3PDA1Nd_ehh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be executed!\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "bO_mOls8KhYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key in the definition is the shape of the input; that is what the model expects as input for each sample in terms of the number of time steps and the number of features.\n",
        "\n",
        "We are working with a univariate series, so the number of features is one, for one variable.\n",
        "\n",
        "The number of time steps as input is the number we chose when preparing our dataset as an argument to the split_sequence() function.\n",
        "\n",
        "The shape of the input for each sample is specified in the input_shape argument on the definition of first hidden layer.\n",
        "\n",
        "We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape:\n",
        "\n"
      ],
      "metadata": {
        "id": "TtN95ZSR_o0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "metadata": {
        "id": "WMSjwL7EIm5B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we define a model with 50 LSTM units in the hidden layer and an output layer that predicts a single numerical value.\n",
        "\n",
        "The model is fit using the efficient Adam version of stochastic gradient descent and optimized using the mean squared error, or ‘mse‘ loss function.\n",
        "\n",
        "Once the model is defined, we can fit it on the training dataset."
      ],
      "metadata": {
        "id": "jKlqlEQEIxzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be executed!\n",
        "# fit model\n",
        "model.fit(X, y, epochs = 200, verbose = 0)"
      ],
      "metadata": {
        "id": "T2MkBfY2KwO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the model is fit, we can use it to make a prediction.\n",
        "\n",
        "We can predict the next value in the sequence by providing the input:\n",
        "[70, 80, 90]\n",
        "\n",
        "And expecting the model to predict something like:\n",
        "[100]\n",
        "\n",
        "The model expects the input shape to be three-dimensional with [samples, timesteps, features], therefore, we must reshape the single input sample before making the prediction."
      ],
      "metadata": {
        "id": "9GiYPS1lK_S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be executed!\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)"
      ],
      "metadata": {
        "id": "kcAu4qzPLAf7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tie all of this together and demonstrate how to develop a Vanilla LSTM for univariate time series forecasting and make a single prediction."
      ],
      "metadata": {
        "id": "-mi-wDKwLf4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "aIs0Fp-CPWCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLIT A UNIVARIATE SEQUENCE INTO SAMPLES:\n",
        "\n",
        "This function will prepare the data from:\n",
        "\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "--------X-----------y\n",
        "[10 20 30] --> 40\n",
        "[20 30 40] --> 50\n",
        "[30 40 50] --> 60\n",
        "[40 50 60] --> 70\n",
        "[50 60 70] --> 80\n",
        "[60 70 80] --> 90"
      ],
      "metadata": {
        "id": "bKbgi0c6LjZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function Testing:\n",
        "# Not part of end code.\n",
        "\n",
        "sequ = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "n_ste = 3\n",
        "\n",
        "Xx, Yy = list(), list()\n",
        "\n",
        "for i in range(len(sequ)):\n",
        "  end_ix = i + n_ste\n",
        "  print(end_ix)\n",
        "  if end_ix > len(sequ)-1:\n",
        "\t\t\tbreak"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_emp4LEpT2Up",
        "outputId": "19c7dde2-2ca6-4fb8-ac28-f05d309c1c42"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "metadata": {
        "id": "h5ISaWIlI35a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DEFINE INPUT SEQUENCE"
      ],
      "metadata": {
        "id": "WEn3j5MKMqak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ],
      "metadata": {
        "id": "JaXP0MvSMuVD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHOOSE A NUMBER OF TIME STEPS"
      ],
      "metadata": {
        "id": "8CeWglOXMw9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 3"
      ],
      "metadata": {
        "id": "_73zJ-eyM0c7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SPLIT INTO SAMPLES"
      ],
      "metadata": {
        "id": "bl3SbhZfM2iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = split_sequence(raw_seq, n_steps)"
      ],
      "metadata": {
        "id": "KmpOWtknM43-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pa3gX6l1PukI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDrIIiS3PlEU",
        "outputId": "ac6b5486-46e9-47e0-add9-17708d82ff09"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[10],\n",
              "        [20],\n",
              "        [30]],\n",
              "\n",
              "       [[20],\n",
              "        [30],\n",
              "        [40]],\n",
              "\n",
              "       [[30],\n",
              "        [40],\n",
              "        [50]],\n",
              "\n",
              "       [[40],\n",
              "        [50],\n",
              "        [60]],\n",
              "\n",
              "       [[50],\n",
              "        [60],\n",
              "        [70]],\n",
              "\n",
              "       [[60],\n",
              "        [70],\n",
              "        [80]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hE_xAkNQb5c",
        "outputId": "5686ea7f-b6c1-4029-dd33-ea959e713356"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f7OGbFMQsBF",
        "outputId": "1c6a6b42-681e-44e3-a740-e64d3eca3f95"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SPLIT FROM **[samples, timesteps]** INTO [samples, timesteps, features]"
      ],
      "metadata": {
        "id": "CrQ11kHXM-NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni3e4QUlQldA",
        "outputId": "1e3211f3-7377-4d5c-b7ca-60459bfe0c4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhLMUrcuQogs",
        "outputId": "c4f4e007-8bab-4111-974a-7833849f0257"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "metadata": {
        "id": "IWJnJp3ANMCr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DEFINE MODEL"
      ],
      "metadata": {
        "id": "AUUxYUwKNPOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "t363_PkENRrm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FIT MODEL"
      ],
      "metadata": {
        "id": "__0-yHJ6NUuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=200, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2-RSOooNXQQ",
        "outputId": "88e11502-47f5-4953-f51f-cb0577060d1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33291cc7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DEMONSTRATE PREDICTION"
      ],
      "metadata": {
        "id": "VA2-aXLZNas8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSMTm-2YK4C1",
        "outputId": "c2d24b75-af0c-4ffd-9fa0-e7f51f33c487"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.02664]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example prepares the data, fits the model, and makes a prediction.\n",
        "\n",
        "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
        "\n",
        "We can see that the model predicts the next value in the sequence."
      ],
      "metadata": {
        "id": "91REUvhXNpBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "7yYkgiwpdRMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BIDRECTIONAL LSTM MODEL**\n",
        "\n",
        "On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.\n",
        "\n",
        "This is called a Bidirectional LSTM.\n",
        "\n",
        "We can implement a Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional.\n",
        "\n",
        "An example of defining a Bidirectional LSTM to read input both forward and backward is as follows."
      ],
      "metadata": {
        "id": "phClU4ITdSWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be executed\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "-dEsSp52NgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate bidirectional lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional\n",
        " \n",
        "# split a univariate sequence\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpgHRYEydeoL",
        "outputId": "77330536-6ff3-4613-ac86-8126ab0dc71e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102.04511]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN LSTM**\n",
        "\n",
        "A convolutional neural network, or CNN for short, is a type of neural network developed for working with two-dimensional image data.\n",
        "\n",
        "The CNN can be very effective at automatically extracting and learning features from one-dimensional sequence data such as univariate time series data.\n",
        "\n",
        "A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret. This hybrid model is called a CNN-LSTM.\n",
        "\n",
        "The first step is to split the input sequences into subsequences that can be processed by the CNN model. For example, we can first split our univariate time series data into input/output samples with four steps as input and one as output. Each sample can then be split into two sub-samples, each with two time steps. The CNN can interpret each subsequence of two time steps and provide a time series of interpretations of the subsequences to the LSTM model to process as input.\n",
        "\n",
        "We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. The input data can then be reshaped to have the required structure:\n",
        "\n",
        "\n",
        "# [samples, subsequences, timesteps, features]"
      ],
      "metadata": {
        "id": "wyJVI-q6gzCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be Executed\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))"
      ],
      "metadata": {
        "id": "uP0lQL79dpeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to reuse the same CNN model when reading in each sub-sequence of data separately.\n",
        "\n",
        "This can be achieved by wrapping the entire CNN model in a TimeDistributed wrapper that will apply the entire model once per input, in this case, once per input subsequence.\n",
        "\n",
        "The CNN model first has a convolutional layer for reading across the subsequence that requires a number of filters and a kernel size to be specified. The number of filters is the number of reads or interpretations of the input sequence. The kernel size is the number of time steps included of each ‘read’ operation of the input sequence.\n",
        "\n",
        "The convolution layer is followed by a max pooling layer that distills the filter maps down to 1/2 of their size that includes the most salient features. These structures are then flattened down to a single one-dimensional vector to be used as a single input time step to the LSTM layer."
      ],
      "metadata": {
        "id": "CShr254ChDR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be Executed\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))"
      ],
      "metadata": {
        "id": "3OAu3zLXhEAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can define the LSTM part of the model that interprets the CNN model’s read of the input sequence and makes a prediction."
      ],
      "metadata": {
        "id": "mUOdx6QDhKPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be Executed\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "vcpLynlFhKyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tie all of this together; the complete example of a CNN-LSTM model for univariate time series forecasting is listed below."
      ],
      "metadata": {
        "id": "QctigAgHhPIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate cnn lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        " \n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDhJjBGyhRTl",
        "outputId": "31a7e2d5-47e8-449e-f8aa-f94778634640"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100.650536]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ConvLSTM**\n",
        "\n",
        "A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly into each LSTM unit.\n",
        "\n",
        "The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with univariate time series forecasting.\n",
        "\n",
        "The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be:\n",
        "[samples, timesteps, rows, columns, features]\n",
        "\n",
        "For our purposes, we can split each sample into subsequences where timesteps will become the number of subsequences, or n_seq, and columns will be the number of time steps for each subsequence, or n_steps. The number of rows is fixed at 1 as we are working with one-dimensional data.\n",
        "\n",
        "We can now reshape the prepared samples into the required structure."
      ],
      "metadata": {
        "id": "9BMjKU29jOfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be Executed\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))"
      ],
      "metadata": {
        "id": "kwve58Oyjc0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define the ConvLSTM as a single layer in terms of the number of filters and a two-dimensional kernel size in terms of (rows, columns). As we are working with a one-dimensional series, the number of rows is always fixed to 1 in the kernel.\n",
        "\n",
        "The output of the model must then be flattened before it can be interpreted and a prediction made."
      ],
      "metadata": {
        "id": "4e-V_FkYjisF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate convlstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D"
      ],
      "metadata": {
        "id": "bps0KIDHjxng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not to be Executed\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu',\n",
        "                     input_shape=(n_seq, 1, n_steps, n_features)))\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "RAXL3D5djlZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The complete example of a ConvLSTM for one-step univariate time series forecasting is listed below."
      ],
      "metadata": {
        "id": "NnI9hTWkj1A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# univariate convlstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        " \n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6psw2qEhY-N",
        "outputId": "93b75048-0301-45e1-a4e2-c3c144f8dfab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.26098]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VUxe5u8Qj7o3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}