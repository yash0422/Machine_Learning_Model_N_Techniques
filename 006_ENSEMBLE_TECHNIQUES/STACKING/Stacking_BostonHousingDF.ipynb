{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b1b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d211e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_df(load):\n",
    "    # Load the input data into the dataframe\n",
    "    df = pd.DataFrame(load.data, columns=load.feature_names)\n",
    "    \n",
    "    # Add the output data into the dataframe\n",
    "    df['label'] = pd.Series(load.target)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "df = dataset_to_df(load_boston())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83f866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  label  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc61f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Getting the output variable\n",
    "y = df['label']\n",
    "\n",
    "# Getting the input variables\n",
    "X = df.drop(['label'], axis=1)\n",
    "\n",
    "# Diving our input and output into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66046af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv = 10, scoring_fit = 'neg_mean_squared_error',\n",
    "                       scoring_test = r2_score, do_probabilities = False):\n",
    "    \n",
    "    gs = GridSearchCV(estimator = model, param_grid = param_grid, cv = cv, n_jobs = -1,\n",
    "                      scoring = scoring_fit, verbose = 2)\n",
    "    \n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    best_model = fitted_model.best_estimator_\n",
    "    \n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    score = scoring_test(y_test_data, pred)\n",
    "    \n",
    "    return [best_model, pred, score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76a8967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1886a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vishal.desai\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703156b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Defining our estimator, the algorithm to optimize\n",
    "models_to_train = [XGBRegressor(), LGBMRegressor(), RandomForestRegressor()]\n",
    "\n",
    "# Defining the hyperparameters to optimize\n",
    "grid_parameters = [\n",
    "    { # XGBoost\n",
    "        'n_estimators': [400, 700, 1000],\n",
    "        'colsample_bytree': [0.7, 0.8],\n",
    "        'max_depth': [15,20,25],\n",
    "        'reg_alpha': [1.1, 1.2, 1.3],\n",
    "        'reg_lambda': [1.1, 1.2, 1.3],\n",
    "        'subsample': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    { # LightGBM\n",
    "        'n_estimators': [400, 700, 1000],\n",
    "        'learning_rate': [0.12],\n",
    "        'colsample_bytree': [0.7, 0.8],\n",
    "        'max_depth': [4],\n",
    "        'num_leaves': [10, 20],\n",
    "        'reg_alpha': [1.1, 1.2],\n",
    "        'reg_lambda': [1.1, 1.2],\n",
    "        'min_split_gain': [0.3, 0.4],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'subsample_freq': [10, 20]\n",
    "    }, \n",
    "    { # Random Forest\n",
    "        'max_depth':[3, 5, 10, 13], \n",
    "        'n_estimators':[100, 200, 400, 600, 900],\n",
    "        'max_features':[2, 4, 6, 8, 10]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a200082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    }
   ],
   "source": [
    "models_preds_scores = []\n",
    "\n",
    "for i, model in enumerate(models_to_train):\n",
    "    params = grid_parameters[i]\n",
    "    \n",
    "    result = algorithm_pipeline(X_train, X_test, y_train, y_test, model, params, cv = 5)\n",
    "    models_preds_scores.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70c8dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBRegressor, Score: 0.8845639246881948\n",
      "Model: LGBMRegressor, Score: 0.8600616387760088\n",
      "Model: RandomForestRegressor, Score: 0.8684175421030795\n"
     ]
    }
   ],
   "source": [
    "for result in models_preds_scores:\n",
    "    print('Model: {0}, Score: {1}'.format(type(result[0]).__name__, result[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68b194",
   "metadata": {},
   "source": [
    "##### Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "175233bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "lgbm = LGBMRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "svr = SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "420c90ec",
   "metadata": {},
   "source": [
    "Note: XGBoost/mlxtend has a bug when trying to mix the packages. That is why we edit the names of the columns of the X_test to f0, f1, etc. – XGBoost internally renames the features of X_train, and if we don't provide the exact same names, it will not run. We also use shuffle=False and random_state=42 for the sake of reproducing the same results displayed in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d03f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingCVRegressor(regressors=(ridge, lasso, svr, rf, lgbm, xgb),\n",
    "                            meta_regressor=xgb, cv=12,\n",
    "                            use_features_in_secondary=True,\n",
    "                            store_train_meta_features=True,\n",
    "                            shuffle=False,\n",
    "                            random_state=42)\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "X_test.columns = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12']\n",
    "pred = stack.predict(X_test)\n",
    "score = r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f6b033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8843782106180298\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
